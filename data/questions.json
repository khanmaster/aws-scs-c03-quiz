{
  "questions": [
    {
      "id": 1,
      "type": "multiple",
      "question": "A business requires a forensic logging solution for hundreds of Docker-based apps running on Amazon EC2. The solution must analyze logs in real time, provide message replay, and persist logs. Which AWS services should be employed to satisfy these requirements? (Select TWO)",
      "options": [
        "Amazon CloudWatch Logs",
        "Amazon Kinesis Data Streams",
        "Amazon SQS",
        "Amazon S3"
      ],
      "correct": [1, 3],
      "explanation": "✅ Correct: B - Real-time stream processing with replay capabilities; D - Persistent storage of logs. ❌ Incorrect: A - CloudWatch is for monitoring, not forensic replay; C - SQS is not designed for log persistence + replay.",
      "keywords": ["forensic", "logging", "Docker", "EC2", "real time", "replay"]
    },
    {
      "id": 2,
      "type": "single",
      "question": "A company developed an application by using AWS Lambda, Amazon S3, Amazon SNS, and Amazon DynamoDB. The data includes PII. The company must remove data that is older than 30 days from the S3 bucket and the DynamoDB table. Which solution will meet this requirement with the MOST operational efficiency?",
      "options": [
        "Use a Lambda function to scan and delete records every 30 days.",
        "Use S3 lifecycle policies and DynamoDB TTL.",
        "Use CloudWatch Events to schedule cleanup scripts.",
        "Enable S3 Intelligent-Tiering and DynamoDB Auto Scaling."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - S3 lifecycle policies automatically remove old objects; DynamoDB TTL deletes expired items. ❌ Incorrect: A and C add complexity; D does not handle deletion.",
      "keywords": ["Lambda", "S3", "SNS", "DynamoDB", "PII", "30 days"]
    },
    {
      "id": 3,
      "type": "multiple",
      "question": "A company is hosting a static website on Amazon S3 and serving it via CloudFront. The company has associated a WAF web ACL to restrict requests to the United States. They are worried that the S3 URL might still be directly accessible. Which combination of steps should the company take to remove direct access to the S3 URL? (Select TWO)",
      "options": [
        "Configure an S3 bucket policy to allow access only from the CloudFront Origin Access Identity (OAI).",
        "Enable versioning on the S3 bucket.",
        "Use an S3 bucket ACL to block all public access.",
        "Use an origin access control (OAC) with signed URLs."
      ],
      "correct": [0, 3],
      "explanation": "✅ Correct: A - Bucket policy + OAI ensures only CloudFront can fetch from S3; D - Origin access control (OAC) with signed URLs adds further restriction. ❌ Incorrect: B - Versioning is unrelated; C - ACL is less effective than bucket policy.",
      "keywords": ["S3", "CloudFront", "WAF", "direct access", "URL"]
    },
    {
      "id": 4,
      "type": "multiple",
      "question": "An organization receives an alert that indicates that an EC2 instance behind an ELB Classic Load Balancer has been compromised. What techniques will limit lateral movement and allow evidence gathering? (Choose TWO)",
      "options": [
        "Remove the instance from the load balancer and terminate it.",
        "Remove the instance from the load balancer, and shut down access to the instance by tightening the security group.",
        "Reboot the instance and check for any Amazon CloudWatch alarms.",
        "Stop the instance and make a snapshot of the root EBS volume."
      ],
      "correct": [1, 3],
      "explanation": "✅ Correct: B - Restricting access prevents lateral movement while keeping the instance for evidence gathering; D - Stopping the instance and creating a snapshot preserves data for forensic analysis. ❌ Incorrect: A - Terminating the instance would destroy evidence; C - Rebooting may overwrite logs and does not prevent lateral movement.",
      "keywords": ["compromised", "EC2", "ELB", "evidence gathering"]
    },
    {
      "id": 5,
      "type": "single",
      "question": "A Development team has asked for help configuring IAM roles and policies in a new AWS account. The team expects to have hundreds of master keys and does not want to manage individual key policies. Which solution allows managing AWS KMS permissions in IAM without editing each key policy?",
      "options": [
        "The account's CMK key policy must allow the account's IAM roles to perform KMS EnableKey.",
        "Newly created CMKs must have a key policy that allows the root principal to perform all actions.",
        "Newly created CMKs must allow the root principal to perform the kms CreateGrant API operation.",
        "Newly created CMKs must mirror the IAM policy of the KMS key administrator."
      ],
      "correct": [2],
      "explanation": "✅ Correct: C - Allowing the root principal to create grants enables IAM policies to control access without editing each key policy. ❌ Incorrect: A - EnableKey alone does not provide the needed granular IAM control; B - Giving full access to root is not recommended for managing multiple keys; D - Mirroring IAM policy is not sufficient to control all CMKs programmatically.",
      "keywords": ["KMS", "CMK", "IAM", "CreateGrant"]
    },
    {
      "id": 6,
      "type": "multiple",
      "question": "An Amazon EC2 instance is part of an Auto Scaling group behind an ALB and is suspected of compromise. Which steps should be taken to investigate? (Choose FOUR)",
      "options": [
        "Detach the elastic network interface from the EC2 instance.",
        "Initiate an EBS volume snapshot of all volumes on the EC2 instance.",
        "Disable any Amazon Route 53 health checks associated with the EC2 instance.",
        "De-register the EC2 instance from the ALB and detach it from the Auto Scaling group.",
        "Attach a security group that has restrictive ingress and egress rules to the EC2 instance.",
        "Add a rule to an AWS WAF to block access to the EC2 instance."
      ],
      "correct": [0, 1, 3, 4],
      "explanation": "✅ Correct: A - Detaching the network interface prevents further lateral movement; B - Snapshotting volumes preserves evidence for analysis; D - Removing from ALB/Auto Scaling prevents impact on live traffic; E - Restrictive SG limits access and prevents further compromise. ❌ Incorrect: C - Health checks do not affect investigation or containment; F - WAF cannot isolate the instance for evidence collection.",
      "keywords": ["EC2", "ALB", "Auto Scaling", "snapshot", "security group"]
    },
    {
      "id": 7,
      "type": "single",
      "question": "A Security Engineer wants users to seamlessly encrypt S3 objects without touching keys directly. The solution must be highly scalable and allow immediate key deletion. Which solution meets these requirements?",
      "options": [
        "Use AWS KMS with AWS managed keys and ScheduleKeyDeletion API with PendingWindowInDays=0.",
        "Use KMS with AWS imported key material and DeletelmportedKeyMaterial API.",
        "Use AWS CloudHSM and PKCS11 API for key deletion.",
        "Use Systems Manager Parameter Store and its API for deletion."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - KMS with imported key material allows users to encrypt without direct key handling and delete imported key material immediately. ❌ Incorrect: A - ScheduleKeyDeletion for AWS managed keys cannot delete immediately; C - CloudHSM requires manual key management; D - Parameter Store is not intended for scalable S3 object encryption.",
      "keywords": ["S3", "encryption", "KMS", "immediate deletion"]
    },
    {
      "id": 8,
      "type": "single",
      "question": "An application uses Amazon Cognito to manage permissions. Customers must be suspended but still able to log in without making changes. Which approach meets these requirements while minimizing complexity?",
      "options": [
        "Create a new database field suspended_status and validate it in application logic.",
        "Add suspended customers to a second Cognito user pool and update login flow.",
        "Use Cognito Sync to push a suspension_status parameter and split IAM policies.",
        "Modify the IAM roles attached to the user to remove all privileges."
      ],
      "correct": [3],
      "explanation": "✅ Correct: D - Modify IAM roles allows login but removes permissions; uses AWS-native separation of authentication and authorization. ❌ Incorrect: A - Custom DB logic works but is less AWS-native and harder to maintain; B - Second user pool adds complexity; C - Cognito Sync is deprecated and unnecessary.",
      "keywords": ["Cognito", "suspend", "IAM", "login"]
    },
    {
      "id": 9,
      "type": "multiple",
      "question": "A company wants to centrally manage secrets for multiple EC2 instances across accounts using AWS. Which is the MOST secure and scalable method? (Choose TWO)",
      "options": [
        "Store secrets in S3 encrypted with AWS KMS and allow EC2 IAM roles access.",
        "Use AWS Secrets Manager and attach IAM roles for cross-account access.",
        "Hardcode secrets in EC2 UserData scripts.",
        "Use Systems Manager Parameter Store (SecureString) with cross-account IAM role access."
      ],
      "correct": [1, 3],
      "explanation": "✅ Correct: B - Secrets Manager scales across accounts, rotates secrets, and IAM roles provide secure access; D - Parameter Store SecureString supports encryption, cross-account access, and IAM-based management. ❌ Incorrect: A - S3 is less manageable and does not provide automatic rotation; C - Hardcoding secrets is insecure and unscalable.",
      "keywords": ["Secrets Manager", "Parameter Store", "IAM", "EC2"]
    },
    {
      "id": 10,
      "type": "multiple",
      "question": "An application uses an RDS database. The Security Engineer wants to ensure encryption at rest and enforce key rotation every 90 days without downtime. Which solution satisfies these requirements? (Choose TWO)",
      "options": [
        "Use AWS-managed KMS CMK with automatic rotation enabled.",
        "Use customer-managed KMS CMK and manually rotate the key every 90 days.",
        "Enable RDS encryption using AWS-managed KMS CMK.",
        "Use Transparent Data Encryption (TDE) on RDS and rotate manually."
      ],
      "correct": [0, 2],
      "explanation": "✅ Correct: A - AWS-managed CMK allows automatic rotation every 90 days without downtime; C - Enabling RDS encryption ensures data at rest is encrypted and integrated with KMS. ❌ Incorrect: B - Manual rotation can cause downtime and is error-prone; D - TDE is only available on certain engines and manual rotation adds complexity.",
      "keywords": ["RDS", "encryption", "KMS", "rotation"]
    },
    {
      "id": 11,
      "type": "single",
      "question": "Which method provides the strongest assurance that AWS Lambda code has not been tampered with after deployment?",
      "options": [
        "Enable AWS CloudTrail logging for Lambda invocations.",
        "Enable Lambda code signing using an AWS Signer profile.",
        "Require IAM role trust policies on Lambda execution role.",
        "Enable VPC endpoint for Lambda."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - Code signing ensures deployed Lambda code matches the signed artifact. ❌ Incorrect: A - CloudTrail logs invocations but does not guarantee code integrity; C - IAM trust policies control access but not code tampering; D - VPC endpoints secure network traffic, unrelated to code integrity.",
      "keywords": ["Lambda", "code signing", "AWS Signer"]
    },
    {
      "id": 12,
      "type": "single",
      "question": "A company must ensure that all S3 objects are encrypted automatically at upload. Which is the MOST scalable approach?",
      "options": [
        "Enable bucket default encryption using SSE-KMS with an AWS-managed key.",
        "Use client-side encryption before uploading to S3.",
        "Add Lambda triggers to encrypt objects post-upload.",
        "Require developers to encrypt objects manually."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Default bucket encryption ensures all new objects are encrypted automatically at scale. ❌ Incorrect: B - Client-side encryption is harder to manage and less scalable; C - Post-upload encryption adds latency and complexity; D - Manual encryption is error-prone and not scalable.",
      "keywords": ["S3", "encryption", "SSE-KMS", "default"]
    },
    {
      "id": 13,
      "type": "single",
      "question": "Which AWS service provides centralized auditing of API calls and user activity across accounts, regions, and services?",
      "options": [
        "AWS Config",
        "AWS CloudTrail",
        "Amazon GuardDuty",
        "AWS CloudWatch"
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - CloudTrail provides centralized logging of all API calls and user activity across AWS. ❌ Incorrect: A - Config tracks resource configurations, not API calls; C - GuardDuty detects threats but does not provide full audit logs; D - CloudWatch monitors metrics and logs, not complete API audit trails.",
      "keywords": ["CloudTrail", "audit", "API calls"]
    },
    {
      "id": 14,
      "type": "single",
      "question": "A company wants to restrict IAM role access for a third-party vendor assuming a role in their AWS account. Which step is the MOST effective to prevent unauthorized access if the ARN is exposed?",
      "options": [
        "Create an IAM user with long-term credentials for the vendor.",
        "Use an external ID in the role trust policy for the vendor.",
        "Require multi-factor authentication in the trust policy.",
        "Restrict role access to the vendor's IP range."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - The external ID prevents unauthorized access even if the ARN is known. ❌ Incorrect: A - IAM user with long-term credentials is less secure and requires manual rotation; C - MFA is useful but does not fully mitigate ARN exposure risk for cross-account roles; D - IP restriction adds security but may fail if vendor IP changes or is spoofed.",
      "keywords": ["IAM role", "external ID", "trust policy", "vendor"]
    },
    {
      "id": 15,
      "type": "multiple",
      "question": "An IAM user cannot download objects from an S3 bucket encrypted with a KMS CMK, while other users can. Which policies should the Security Engineer check? (Choose THREE)",
      "options": [
        "The CMK policy",
        "The VPC endpoint policy",
        "The S3 bucket policy",
        "The S3 ACL",
        "The IAM policy"
      ],
      "correct": [0, 2, 4],
      "explanation": "✅ Correct: A - CMK policy must allow the user to decrypt objects; C - S3 bucket policy may deny access to specific users; E - IAM policy must grant proper permissions to access objects and decrypt with KMS. ❌ Incorrect: B - VPC endpoint policy may restrict access but typically does not cause user-specific failures; D - ACLs are less commonly used; bucket policies and KMS are more likely causes.",
      "keywords": ["S3", "CMK", "IAM", "bucket policy", "ACL"]
    },
    {
      "id": 16,
      "type": "single",
      "question": "While analyzing the AWS account root user, what provides the highest level of security?",
      "options": [
        "Create a new IAM user with admin permissions; delete root password",
        "Create a new IAM user; modify permissions of existing IAM users",
        "Replace root access key; delete root password",
        "Create a new IAM user with admin permissions; enable MFA for root"
      ],
      "correct": [3],
      "explanation": "✅ Correct: D - New IAM admin user plus root MFA ensures highest security. ❌ Incorrect: A - Deleting root password is risky; MFA is critical; B - Modifying existing IAM users does not protect root access; C - Access key rotation alone does not secure root account.",
      "keywords": ["root user", "IAM user", "MFA"]
    },
    {
      "id": 17,
      "type": "multiple",
      "question": "Users need to authenticate via SAML to a web app with S3 static content, API Gateway, and DynamoDB. Which steps are required? (Choose THREE)",
      "options": [
        "Create custom authorization service with Lambda",
        "Configure SAML IdP in Cognito to map attributes to user pool",
        "Configure SAML IdP to add Cognito user pool as a relying party",
        "Configure Cognito identity pool to integrate with social login",
        "Update DynamoDB to store user email/password",
        "Update API Gateway to use COGNITO_USER_POOLS authorizer"
      ],
      "correct": [1, 2, 5],
      "explanation": "✅ Correct: B - Attribute mapping allows proper claims from SAML IdP; C - User pool must be a relying party for SAML authentication; F - API Gateway authorizer enforces user pool authentication for API calls. ❌ Incorrect: A - Custom Lambda authorization is unnecessary; D - Social login is unrelated; E - Storing passwords manually in DynamoDB violates SAML use.",
      "keywords": ["SAML", "Cognito", "identity pool", "API Gateway", "user pool"]
    },
    {
      "id": 18,
      "type": "single",
      "question": "Ping from on-premises host to EC2 fails. Flow log shows outbound rejected. What action allows the ping to succeed?",
      "options": [
        "Allow inbound ICMP in EC2 security group",
        "Allow outbound ICMP in EC2 security group",
        "Allow inbound ICMP in VPC NACL",
        "Allow outbound ICMP in VPC NACL"
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - Outbound ICMP from EC2 security group allows ping replies to leave the instance. ❌ Incorrect: A - Inbound ICMP may already be allowed; the issue is outbound; C - NACL inbound may not be blocking; security group is primary issue; D - NACL outbound alone may not suffice if SG blocks outbound.",
      "keywords": ["EC2", "ICMP", "security group", "VPC NACL"]
    },
    {
      "id": 19,
      "type": "single",
      "question": "A Java app running on EC2 uses RDS MySQL. How should credentials be handled securely?",
      "options": [
        "Store in environment variables in EC2 UserData",
        "Store in AWS Secrets Manager; EC2 IAM role access",
        "Hardcode credentials in application properties",
        "Store in S3 with encryption; download on startup"
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - Secrets Manager with IAM role access provides secure, auditable, and scalable credential management. ❌ Incorrect: A - Environment variables in UserData are insecure and exposed; C - Hardcoding is insecure and unmanageable; D - S3 retrieval adds latency and is less secure.",
      "keywords": ["Secrets Manager", "EC2 IAM role", "RDS credentials"]
    },
    {
      "id": 20,
      "type": "multiple",
      "question": "A Security Engineer must prevent accidental S3 bucket deletion. Which methods are effective? (Choose TWO)",
      "options": [
        "Enable S3 bucket versioning",
        "Enable MFA delete",
        "Add a bucket policy to deny delete action",
        "Use client-side encryption"
      ],
      "correct": [0, 1],
      "explanation": "✅ Correct: A - Versioning preserves objects even if deleted accidentally; B - MFA delete requires authentication for delete operations, preventing accidental deletion. ❌ Incorrect: C - Bucket policies alone may not prevent deletion if IAM user has full permissions; D - Encryption does not prevent deletion.",
      "keywords": ["S3", "MFA delete", "versioning", "bucket deletion"]
    },
    {
      "id": 21,
      "type": "single",
      "question": "A security administrator tries to connect to a Linux EC2 instance with SSH and receives: 'Error: Unprotected private key file – Permissions for 'ssh/my_private_key.pem' are too open.' Which command resolves this issue?",
      "options": [
        "chmod 0040 ssh/my_private_key.pem",
        "chmod 0400 ssh/my_private_key.pem",
        "chmod 0004 ssh/my_private_key.pem",
        "chmod 0777 ssh/my_private_key.pem"
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - chmod 0400 sets the file readable only by the owner, as SSH requires. ❌ Incorrect: A - Gives read access to the group but not the owner; C - World-readable, insecure, rejected by SSH; D - Full access to everyone; insecure.",
      "keywords": ["SSH", "private key", "permissions", "chmod"]
    },
    {
      "id": 22,
      "type": "single",
      "question": "Company A has an AWS account (Account A) and recently acquired Company B (Account B). Company B stores its files in an Amazon S3 bucket. The administrators need to give a user from Account A full access to the S3 bucket in Account B. After adjusting IAM permissions for the user in Account A, the user still cannot access files. Which solution resolves this issue?",
      "options": [
        "In Account B, create a bucket ACL to allow the user from Account A to access the S3 bucket.",
        "In Account B, create an object ACL to allow the user from Account A to access all objects in the S3 bucket.",
        "In Account B, create a bucket policy to allow the user from Account A to access the S3 bucket.",
        "In Account B, create a user policy to allow the user from Account A to access the S3 bucket."
      ],
      "correct": [2],
      "explanation": "✅ Correct: C - Bucket policies grant cross-account access to users, which IAM alone cannot enforce. ❌ Incorrect: A - ACLs are outdated; bucket policies are preferred for cross-account access; B - Object ACL requires configuring each object individually; inefficient; D - User policy in Account A do not override bucket policies in Account B.",
      "keywords": ["cross-account", "S3 bucket", "bucket policy", "IAM"]
    },
    {
      "id": 23,
      "type": "single",
      "question": "A company has a web application using Amazon CloudFront and ECS behind an ALB. The ALB terminates TLS. The security engineer needs to ensure application content is accessible only through CloudFront and never directly via the ALB. What is the MOST secure solution?",
      "options": [
        "Add an origin custom header. Viewer Protocol policy HTTP & HTTPS. Origin protocol HTTPS only. Validate CloudFront header.",
        "Add an origin custom header. Viewer Protocol HTTPS only. Origin protocol match viewer. Validate CloudFront header.",
        "Add an origin custom header. Viewer Protocol redirect HTTP to HTTPS. Origin protocol HTTP only. Validate CloudFront header.",
        "Add an origin custom header. Viewer Protocol redirect HTTP to HTTPS. Origin protocol HTTPS only. Validate CloudFront header."
      ],
      "correct": [3],
      "explanation": "✅ Correct: D - Add an origin custom header, redirect HTTP to HTTPS, origin HTTPS only restricts access to CloudFront only; direct access to ALB is blocked, and HTTPS ensures secure traffic. ❌ Incorrect: Other options have security gaps or don't fully restrict direct ALB access.",
      "keywords": ["CloudFront", "ALB", "TLS", "origin header"]
    },
    {
      "id": 24,
      "type": "multiple",
      "question": "A company is using AWS Secrets Manager to store secrets for its RDS database. Secrets must rotate every 3 months. Which solutions allow secure rotation? (Select TWO)",
      "options": [
        "RDS in public subnet, Lambda outside VPC, scheduled every 3 months.",
        "RDS in private subnet, Lambda inside VPC with NAT gateway, schedule every 3 months.",
        "RDS in private subnet, Lambda outside VPC, private subnet with internet gateway, scheduled every 3 months.",
        "RDS in private subnet, Lambda inside VPC, schedule quarterly.",
        "RDS in private subnet, Lambda inside VPC, Secrets Manager interface endpoint, schedule every 3 months."
      ],
      "correct": [1, 4],
      "explanation": "✅ Correct: B - Lambda inside VPC with NAT can access private RDS and internet if needed; E - Lambda inside VPC with Secrets Manager endpoint can access Secrets Manager securely without NAT gateway. ❌ Incorrect: A, C, D - Public subnet or Lambda outside VPC may expose secrets or fail to access private RDS securely.",
      "keywords": ["Secrets Manager", "RDS", "Lambda", "VPC", "rotation"]
    },
    {
      "id": 25,
      "type": "single",
      "question": "You must ensure all data is encrypted at rest and in transit for IAM resources. Which is a correct implementation?",
      "options": [
        "Use S3 SSE and SSL for data in transit.",
        "SSL termination on ELB.",
        "Enabling Proxy Protocol.",
        "Enabling sticky sessions on load balancer."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Use S3 SSE and SSL encrypts data at rest; SSL encrypts in transit. ❌ Incorrect: B, C, D - These options don't provide complete encryption at rest and in transit.",
      "keywords": ["encryption", "at rest", "in transit", "SSE", "SSL"]
    },
    {
      "id": 26,
      "type": "multiple",
      "question": "A security engineer configures S3 Cross-Region Replication (CRR) with SSE-KMS encrypted objects. Unencrypted objects replicate successfully, but encrypted objects do not. Which steps should remediate this? (Select THREE)",
      "options": [
        "Change replication configuration to use key in us-east-1 for destination.",
        "Grant IAM role kms:Encrypt for key in us-west-2.",
        "Grant IAM role s3:GetObjectVersionForReplication on source bucket.",
        "Grant IAM role kms:Decrypt for key in us-east-1.",
        "Change key policy in us-east-1 to grant decrypt to engineer's IAM account."
      ],
      "correct": [1, 2, 3],
      "explanation": "✅ Correct: B - Grant IAM role kms:Encrypt required to encrypt objects in destination; C - Grant IAM role s3:GetObjectVersionForReplication required to replicate source objects; D - Grant IAM role kms:Decrypt required to read source SSE-KMS objects for replication. ❌ Incorrect: A, E - Changing key or policy alone does not fix replication permissions.",
      "keywords": ["S3", "CRR", "SSE-KMS", "replication", "IAM role"]
    },
    {
      "id": 27,
      "type": "single",
      "question": "A company is testing its incident response plan for compromised credentials. The company runs a database on an Amazon EC2 instance and stores the sensitive database credentials as a secret in AWS Secrets Manager. The secret has rotation configured with an AWS Lambda function. The EC2 instance and the Lambda function are deployed in the same private subnet. The VPC has a Secrets Manager VPC endpoint. A security engineer discovers that the secret cannot rotate. Which solution will resolve this error?",
      "options": [
        "Ensure that the Lambda function has network access to the database instance.",
        "Add the SecretsManagerReadWrite policy to the Lambda execution role.",
        "Add the Lambda function to the database security group.",
        "Enable rotation on the database instead of Secrets Manager."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Lambda must be able to connect to the DB to perform rotation. ❌ Incorrect: B - IAM isn't the root cause when the function cannot connect over the network; C - Security group configuration is part of network access; D - Rotation must be coordinated via Secrets Manager / Lambda.",
      "keywords": ["Secrets Manager", "rotation", "Lambda", "database", "network access"]
    },
    {
      "id": 28,
      "type": "multiple",
      "question": "A company needs a forensic-logging solution for hundreds of applications running in Docker on Amazon EC2. The solution must perform real-time analytics on the logs, must support the replay of messages, and must persist the logs. Which AWS services should be used to meet these requirements? (Select TWO)",
      "options": [
        "Amazon CloudWatch Logs",
        "Amazon Kinesis Data Streams",
        "Amazon SQS",
        "Amazon S3"
      ],
      "correct": [1, 3],
      "explanation": "✅ Correct: B - Kinesis provides real-time processing and replay capabilities; D - S3 provides durable persistent storage for forensic evidence. ❌ Incorrect: A - CloudWatch is useful for monitoring but not ideal for replay scenarios; C - SQS is not designed for large-scale log replay and persistence.",
      "keywords": ["forensic", "logging", "Docker", "EC2", "analytics", "replay"]
    },
    {
      "id": 29,
      "type": "single",
      "question": "A company is evaluating the use of AWS Systems Manager Session Manager to gain access to the company's Amazon EC2 instances. However, until the company implements the change, the company must protect the key file for the EC2 instances from read and write operations by any other users. When a security administrator tries to connect to a critical EC2 Linux instance during an emergency, the security administrator receives the following error: 'Error Unprotected private key file – Permissions for 'ssh/my_private_key.pem' are too open'. Which command should the security administrator use to modify the private key file permissions to resolve this error?",
      "options": [
        "chmod 400 ssh/my_private_key.pem",
        "chmod 600 ssh/my_private_key.pem",
        "chmod 700 ssh/my_private_key.pem",
        "chmod 744 ssh/my_private_key.pem"
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - chmod 400 restricts the file to be readable only by the owner, which SSH requires for private keys. ❌ Incorrect: B - chmod 600 is sometimes acceptable, but 400 is the stricter recommended mode for private keys; C - chmod 700 grants execute permission, not appropriate; D - chmod 744 leaves world-readable bits set and is not secure for private keys.",
      "keywords": ["Session Manager", "EC2", "Linux", "private key", "permissions"]
    },
    {
      "id": 30,
      "type": "single",
      "question": "A company deploys a set of standard IAM roles in AWS accounts. The IAM roles are based on job functions within the company. To balance operational efficiency and security, a security engineer implemented AWS Organizations SCPs to restrict access to critical security services in all company accounts. All of the company's accounts and OUs within AWS Organizations have a default FullAWSAccess SCP attached. The security engineer needs to ensure that no one can disable Amazon GuardDuty and AWS Security Hub, without overriding other permissions. Which SCP should the security engineer attach?",
      "options": [
        "An SCP that denies guardduty:DeleteDetector and securityhub:DisableSecurityHub.",
        "An SCP that allows only SecurityHub:Enable and GuardDuty:Enable.",
        "An SCP that allows all security services.",
        "An SCP that denies all actions except Security Hub and GuardDuty."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Explicitly denying the API calls that disable those services prevents tampering while leaving other permissions intact. ❌ Incorrect: B - Allowing only those actions would be too restrictive and override normal account policies; C - Too broad; does not prevent disabling; D - Overly restrictive and breaks other functionality.",
      "keywords": ["IAM roles", "SCP", "Organizations", "GuardDuty", "Security Hub"]
    },
    {
      "id": 31,
      "type": "single",
      "question": "A company is building a data processing application that uses AWS Lambda functions. The Lambda functions need to communicate with an Amazon RDS DB instance deployed within a VPC in the same account. Which solution meets these requirements in the MOST secure way?",
      "options": [
        "Use a Lambda function with public internet access to connect to RDS.",
        "Place the Lambda function in the same VPC with appropriate security group rules.",
        "Expose RDS publicly and use TLS.",
        "Use API Gateway as a proxy for the Lambda to RDS communication."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - Deploying Lambda in the same VPC and using security groups keeps traffic private and secure. ❌ Incorrect: A - Public internet access is unnecessary and less secure; C - Public RDS exposes attack surface even if TLS is used; D - API Gateway is unnecessary for direct private DB access and adds complexity.",
      "keywords": ["Lambda", "RDS", "VPC", "secure communication"]
    },
    {
      "id": 32,
      "type": "multiple",
      "question": "A company has an application that uses an Amazon RDS PostgreSQL database. During a security review, the company discovers that the DB instance is not encrypting data at rest. The company must enable encryption for existing and new data. Which combination of options can the company use? (Select TWO)",
      "options": [
        "Create a snapshot of the DB instance, copy it with encryption, and restore a new encrypted instance.",
        "Enable encryption directly on the existing instance.",
        "Enable encryption on RDS using KMS CMKs.",
        "Migrate the data to a new encrypted DB instance."
      ],
      "correct": [0, 3],
      "explanation": "✅ Correct: A - Create a snapshot, copy with encryption, and restore to an encrypted instance; D - Migrating data to a new encrypted instance is a valid approach. ❌ Incorrect: B - You cannot toggle encryption on an existing unencrypted RDS instance; C - KMS CMKs are used, but the practical methods are snapshot-copy or migration.",
      "keywords": ["RDS", "PostgreSQL", "encryption", "data at rest"]
    },
    {
      "id": 33,
      "type": "single",
      "question": "Which of the following bucket policies will ensure that objects being uploaded to a bucket called 'demo' are encrypted?",
      "options": [
        "Deny requests without x-amz-server-side-encryption header.",
        "Allow all actions if SSL is used.",
        "Enable S3 versioning.",
        "Apply default encryption in console only."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - A deny statement that blocks uploads without the SSE header enforces encryption on upload. ❌ Incorrect: B - SSL protects transit but not server-side encryption at rest; C - Versioning is not related to encryption enforcement; D - Console default helps but a policy is needed to enforce uploads from all clients.",
      "keywords": ["S3", "bucket policy", "encryption"]
    },
    {
      "id": 34,
      "type": "multiple",
      "question": "A company uses AWS Organizations to manage a multi-account AWS environment. The company needs to automatically deploy a set of 10 AWS Config rules to all existing and future accounts. The solution must also turn on AWS Config automatically during account creation. Which combination of steps will meet these requirements? (Select TWO)",
      "options": [
        "Use AWS Config Aggregator with delegated admin.",
        "Use AWS CloudFormation StackSets to deploy Config rules.",
        "Use Service Control Policies (SCPs) to enforce rules.",
        "Use AWS Config Organization Managed Rules."
      ],
      "correct": [1, 3],
      "explanation": "✅ Correct: B - CloudFormation StackSets can deploy the rule resources across all accounts; D - Organization managed rules make it simple to apply Config rules across all accounts including new ones. ❌ Incorrect: A - Aggregator collects and aggregates, it doesn't deploy rules; C - SCPs cannot enforce Config rule deployment.",
      "keywords": ["Organizations", "AWS Config", "rules", "automation"]
    },
    {
      "id": 35,
      "type": "multiple",
      "question": "A company has two AWS accounts. In Account-1, Amazon EC2 Auto Scaling launches using a service-linked role. In Account-2, Amazon EBS volumes are encrypted with an AWS KMS key. A security engineer needs to ensure that the service-linked role can launch instances with these encrypted volumes. Which combination of steps should the engineer take? (Select TWO)",
      "options": [
        "Add a key policy to allow Account-1 service-linked role to use the CMK.",
        "Create a resource policy on EC2 to allow encrypted volume access.",
        "Grant IAM permission for kms:Decrypt and kms:CreateGrant in Account-2.",
        "Create an SCP to enforce encryption on Auto Scaling."
      ],
      "correct": [0, 2],
      "explanation": "✅ Correct: A - The CMK key policy must allow the external role (or principal) to use the key; C - The role needs the proper KMS permissions (e.g., kms:CreateGrant) to attach encrypted volumes. ❌ Incorrect: B - EC2 does not have a resource policy mechanism for this purpose; D - SCPs are not the correct tool for granting cross-account KMS usage.",
      "keywords": ["EC2", "Auto Scaling", "KMS", "EBS", "cross account"]
    },
    {
      "id": 36,
      "type": "multiple",
      "question": "Which of the following are valid configurations for using SSL certificates with Amazon CloudFront? (Select THREE)",
      "options": [
        "Default CloudFront certificate (*.cloudfront.net)",
        "ACM certificate in us-east-1",
        "ACM certificate in any Region",
        "IAM certificate uploaded to CloudFront"
      ],
      "correct": [0, 1, 3],
      "explanation": "✅ Correct: A - CloudFront's default certificate covers *.cloudfront.net; B - ACM certificates used by CloudFront must be in us-east-1; D - IAM-uploaded certificates can be used with CloudFront (legacy option). ❌ Incorrect: C - ACM certs in other regions cannot be associated with CloudFront distributions.",
      "keywords": ["CloudFront", "SSL", "certificates", "ACM"]
    },
    {
      "id": 37,
      "type": "single",
      "question": "A company uses AWS SSO for access to accounts. The company wants to enforce MFA for access to the AWS Management Console, but not require MFA for CLI access. How can this requirement be met?",
      "options": [
        "Configure different permission sets for console and CLI, enforce MFA on console set.",
        "Configure AWS SSO MFA only for console access.",
        "Use an SCP to enforce MFA only on console actions.",
        "Use IAM password policy for console MFA."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Create separate permission sets/roles and require MFA for the console permission set; CLI roles can omit the MFA requirement. ❌ Incorrect: B - AWS SSO's MFA settings are applied at sign-in; splitting by permission set is the practical approach; C - SCPs cannot differentiate console vs CLI; D - Password policies do not enforce MFA.",
      "keywords": ["SSO", "MFA", "console", "CLI"]
    },
    {
      "id": 38,
      "type": "single",
      "question": "A company must secure sensitive objects stored in Amazon S3. The security team requires that all objects are encrypted at rest and that keys are rotated automatically each year. Which solution meets these requirements?",
      "options": [
        "Use SSE-S3 (Amazon S3 managed keys).",
        "Use SSE-KMS with AWS managed CMKs with automatic rotation.",
        "Use client-side encryption libraries.",
        "Use default encryption with S3."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - SSE-KMS with customer-managed CMKs (or AWS-managed CMKs where rotation is enabled) supports key rotation. ❌ Incorrect: A - SSE-S3 does not provide annual rotation control; C - Client-side adds operational burden; D - Default encryption alone doesn't meet rotation requirements.",
      "keywords": ["S3", "encryption", "rotation", "keys"]
    },
    {
      "id": 39,
      "type": "single",
      "question": "A developer is using AWS Lambda and needs to securely store database connection strings. The solution must minimize operational overhead. Which service should the developer use?",
      "options": [
        "Store in AWS Secrets Manager.",
        "Store in Amazon S3 with SSE.",
        "Store in Lambda environment variables.",
        "Store in DynamoDB."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - AWS Secrets Manager is designed for secrets, supports rotation and minimal ops overhead. ❌ Incorrect: B - S3 is not a secrets manager; C - Env vars are less secure unless encrypted with a KMS key and managed carefully; D - DynamoDB is not intended for secrets management.",
      "keywords": ["Lambda", "database", "secrets", "secure storage"]
    },
    {
      "id": 40,
      "type": "single",
      "question": "A company has several accounts in AWS Organizations. The security team wants to ensure that all Amazon S3 buckets are encrypted by default across accounts. Which solution will meet this requirement with the LEAST operational overhead?",
      "options": [
        "Use AWS Config rule 's3-bucket-server-side-encryption-enabled'.",
        "Use SCP to enforce encryption.",
        "Require all teams to use SSE in policies.",
        "Use CloudWatch Events to trigger Lambda that applies bucket policies."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - An AWS Config rule can detect non-compliant buckets and be combined with remediation automation. ❌ Incorrect: B - SCPs can't enforce individual bucket encryption settings; C - Requiring teams manually is error-prone; D - Custom automation adds overhead compared to Config managed remediation.",
      "keywords": ["Organizations", "S3", "encryption", "compliance"]
    },
    {
      "id": 41,
      "type": "multiple",
      "question": "A company stores sensitive financial data in Amazon S3. The company wants to ensure that all access to this data is logged and that unauthorized requests are denied. Which combination of steps should the company take? (Select TWO)",
      "options": [
        "Enable server access logging on the bucket.",
        "Enable CloudTrail data events for the S3 bucket.",
        "Use default encryption.",
        "Create an S3 bucket policy to deny requests without encryption headers."
      ],
      "correct": [1, 3],
      "explanation": "✅ Correct: B - CloudTrail data events capture object-level API activity for auditing; D - A bucket policy that denies unencrypted requests helps block unauthorized/unwanted uploads. ❌ Incorrect: A - Server access logs are useful but are less granular than CloudTrail data events; C - Default encryption alone doesn't provide access logging or deny unauthorized requests.",
      "keywords": ["S3", "sensitive", "logging", "unauthorized"]
    },
    {
      "id": 42,
      "type": "multiple",
      "question": "A company is developing a multi-account strategy. The company wants to centralize security logging. Which AWS service combination can achieve this? (Select TWO)",
      "options": [
        "Use AWS CloudTrail with centralized logging bucket.",
        "Use Amazon GuardDuty with a delegated administrator.",
        "Use AWS Config aggregator only.",
        "Use Amazon Inspector across accounts."
      ],
      "correct": [0, 1],
      "explanation": "✅ Correct: A - Centralized CloudTrail to a single S3 bucket is the standard approach for unified API logs; B - GuardDuty delegated admin centralizes threat findings across accounts. ❌ Incorrect: C - Config aggregator collects compliance data but isn't a full logging solution by itself; D - Inspector provides vulnerability assessments rather than general security logging.",
      "keywords": ["multi-account", "logging", "centralized", "CloudTrail", "GuardDuty"]
    },
    {
      "id": 43,
      "type": "single",
      "question": "A company has compliance requirements that mandate encryption of all EBS volumes. Which solution provides the MOST operationally efficient way to ensure compliance?",
      "options": [
        "Use an SCP to enforce encryption.",
        "Enable EBS encryption by default in the account.",
        "Require developers to specify encryption in launch templates.",
        "Enable Config rule and remediate noncompliance manually."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - Enabling EBS encryption by default in the account ensures all new volumes are encrypted without relying on user action. ❌ Incorrect: A - SCPs don't enforce encryption settings on resource creation in the same way; C - Developer-managed solutions are error-prone; D - Manual remediation requires more operational effort.",
      "keywords": ["EBS", "encryption", "compliance"]
    },
    {
      "id": 44,
      "type": "single",
      "question": "A company is using AWS CloudTrail to monitor API calls. The security team wants to ensure that CloudTrail logs cannot be modified or deleted once delivered to S3. Which solution will meet this requirement?",
      "options": [
        "Enable S3 bucket versioning and MFA delete.",
        "Enable CloudTrail log file validation.",
        "Enable S3 server-side encryption.",
        "Use S3 lifecycle policies to archive logs."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Versioning + MFA delete helps prevent tampering/deletion of CloudTrail logs in S3. ❌ Incorrect: B - Log file validation detects tampering but does not prevent deletion; C - Encryption protects confidentiality, not immutability; D - Lifecycle rules move or delete objects and do not prevent tampering.",
      "keywords": ["CloudTrail", "logs", "immutable", "S3"]
    },
    {
      "id": 45,
      "type": "single",
      "question": "A company must comply with regulatory requirements that require encryption of data in transit between on-premises and AWS. The company uses AWS Direct Connect. Which solution meets this requirement?",
      "options": [
        "Use Direct Connect with private VIF only.",
        "Use VPN over Direct Connect.",
        "Use MACsec on Direct Connect.",
        "Use TLS only on applications."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - A VPN tunnel over Direct Connect provides encryption for traffic traversing the link. ❌ Incorrect: A - Private VIF does not provide encryption; C - MACsec availability varies and is not the general recommended approach for link encryption in all regions; D - TLS at the application layer may be required, but VPN over Direct Connect ensures encryption across the link.",
      "keywords": ["Direct Connect", "encryption", "in transit"]
    },
    {
      "id": 46,
      "type": "single",
      "question": "A company is running workloads in a VPC. The company wants to implement network segmentation. Which solution provides the MOST secure and scalable option?",
      "options": [
        "Use subnets with security groups and NACLs.",
        "Use multiple VPCs with VPC peering.",
        "Use multiple accounts with AWS Organizations and VPC peering.",
        "Use Transit Gateway with multiple VPCs and route tables."
      ],
      "correct": [3],
      "explanation": "✅ Correct: D - Transit Gateway with route table-based segmentation scales well and centralizes routing/security controls. ❌ Incorrect: A - Subnets + SGs/NACLs provide segmentation but aren't as scalable for large architectures; B - VPC peering does not scale as Transit Gateway does; C - Multiple accounts is good for isolation but pairing with Transit Gateway yields the scalable network architecture.",
      "keywords": ["VPC", "segmentation", "network"]
    },
    {
      "id": 47,
      "type": "single",
      "question": "A security engineer is implementing a solution that requires storing encryption keys outside of AWS but still needs to use them with AWS services. Which service should the engineer use?",
      "options": [
        "AWS KMS with custom key store backed by AWS CloudHSM.",
        "AWS Secrets Manager.",
        "AWS Certificate Manager.",
        "AWS CloudTrail."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - KMS with a custom key store backed by CloudHSM allows keys to be kept in HSMs under customer control while integrating with AWS. ❌ Incorrect: B - Secrets Manager stores secrets but isn't an HSM-backed external key store; C - ACM manages TLS certs, not general-purpose encryption keys outside AWS; D - CloudTrail is for logging, not key storage.",
      "keywords": ["encryption keys", "external", "CloudHSM"]
    },
    {
      "id": 48,
      "type": "multiple",
      "question": "A company wants to enforce the principle of least privilege across its AWS accounts. Which combination of steps will help achieve this goal? (Select TWO)",
      "options": [
        "Use IAM Access Analyzer to review unused permissions.",
        "Enable AWS SSO with permission sets.",
        "Use IAM inline policies for all users.",
        "Use AWS Config rules for IAM compliance."
      ],
      "correct": [0, 1],
      "explanation": "✅ Correct: A - IAM Access Analyzer helps identify unused/over-permissive access so you can reduce permissions; B - AWS SSO (IAM Identity Center) with permission sets helps manage least-privilege roles centrally. ❌ Incorrect: C - Inline policies for all users are hard to manage at scale; D - Config rules help audit compliance but don't by themselves implement least-privilege role design.",
      "keywords": ["least privilege", "Access Analyzer", "SSO", "permission sets"]
    },
    {
      "id": 49,
      "type": "single",
      "question": "A company uses Amazon RDS for MySQL as a database engine for its applications. A recent security audit revealed an RDS instance that is not compliant with company policy for encrypting data at rest. A security engineer at the company needs to ensure that all existing RDS databases are encrypted using server-side encryption. Which step should the security engineer take to accomplish this?",
      "options": [
        "Create an AWS Config rule to detect the creation of encrypted RDS databases.",
        "Use AWS Systems Manager State Manager to detect RDS database encryption configuration drift.",
        "Create a read replica for the existing unencrypted RDS database and enable replica encryption in the process.",
        "Take a snapshot of the unencrypted RDS database. Copy the snapshot and enable snapshot encryption in the process. Restore the database instance from the newly created encrypted snapshot."
      ],
      "correct": [3],
      "explanation": "✅ Correct: D - Taking a snapshot, copying it with encryption enabled, and restoring ensures the database is encrypted at rest. ❌ Incorrect: A - Config rules detect but don't remediate; B - Systems Manager cannot enforce or remediate RDS encryption; C - While creating a read replica can encrypt some engines, snapshots are the recommended method for MySQL.",
      "keywords": ["RDS", "MySQL", "encryption", "snapshot"]
    },
    {
      "id": 50,
      "type": "single",
      "question": "A company has a large fleet of Linux Amazon EC2 instances and Windows EC2 instances that run in private subnets. The company wants all remote administration to be performed as securely as possible in the AWS Cloud. Which solution will meet these requirements?",
      "options": [
        "Do not use SSH-RSA private keys during the launch of new instances. Implement AWS Systems Manager Session Manager.",
        "Generate new SSH-RSA private keys for existing instances. Implement AWS Systems Manager Session Manager.",
        "Do not use SSH-RSA private keys during the launch of new instances. Configure EC2 Instance Connect.",
        "Generate new SSH-RSA private keys for existing instances. Configure EC2 Instance Connect."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Session Manager allows secure remote administration without relying on SSH keys. ❌ Incorrect: B - Using SSH keys for existing instances is less secure and operationally complex; C - Instance Connect requires SSH keys for access; D - Using SSH keys is not as secure as Session Manager.",
      "keywords": ["EC2", "Linux", "Windows", "Session Manager", "remote administration"]
    },
    {
      "id": 51,
      "type": "multiple",
      "question": "An AWS Lambda function that creates image thumbnails from larger images. The Lambda function needs read and write access to an Amazon S3 bucket in the same AWS account. Which solutions will provide the Lambda function this access? (Select TWO)",
      "options": [
        "Create an IAM user that has only programmatic access. Create a new access key pair. Add environmental variables to the Lambda function with the access key ID and secret access key.",
        "Generate an Amazon EC2 key pair. Store the private key in AWS Secrets Manager. Modify the Lambda function to retrieve the private key from Secrets Manager.",
        "Create an IAM role for the Lambda function. Attach an IAM policy that allows access to the S3 bucket.",
        "Create an IAM role for the Lambda function. Attach a bucket policy to the S3 bucket to allow access. Specify the function's IAM role as the principal."
      ],
      "correct": [2, 3],
      "explanation": "✅ Correct: C - IAM role with policy grants Lambda function access to S3 securely; D - Bucket policy can also allow the Lambda function's IAM role access. ❌ Incorrect: A - Using IAM user credentials in environment variables is insecure; B - Private keys via Secrets Manager are not needed for Lambda → S3 access.",
      "keywords": ["Lambda", "S3", "IAM role", "bucket policy", "access"]
    },
    {
      "id": 52,
      "type": "single",
      "question": "A security engineer is designing an IAM policy for a script that will use the AWS CLI. The script currently assumes an IAM role that is attached to three AWS managed IAM policies: AmazonEC2FullAccess, AmazonDynamoDBFullAccess, and AmazonVPCFullAccess. The security engineer needs to construct a least privilege IAM policy that will replace the AWS managed IAM policies. Which solution will meet these requirements in the MOST operationally efficient way?",
      "options": [
        "In AWS CloudTrail, create a trail for management events. Run the script with the existing AWS managed IAM policies. Use IAM Access Analyzer to generate a new IAM policy that is based on access activity in the trail.",
        "Remove the existing AWS managed IAM policies from the role. Attach the IAM Access Analyzer Role Policy Generator to the role. Run the script. Return to IAM Access Analyzer and generate a least privilege IAM policy.",
        "Create an account analyzer in IAM Access Analyzer. Create an archive rule that has a filter that checks whether the Principal Arn value matches the ARN of the role. Run the script.",
        "In AWS CloudTrail, create a trail for management events. Remove the existing AWS managed IAM policies from the role. Run the script. Find the authorization failure in the trail event. Create a new IAM policy that includes the action and resource that caused the authorization failure."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - IAM Access Analyzer can generate a least privilege policy based on actual usage in CloudTrail efficiently. ❌ Incorrect: B - Operationally less efficient; extra manual steps required; C - Does not produce a usable policy for the role automatically; D - Manual trial-and-error process is inefficient.",
      "keywords": ["IAM", "least privilege", "Access Analyzer", "CloudTrail"]
    },
    {
      "id": 53,
      "type": "multiple",
      "question": "A company that uses AWS Organizations wants to see AWS Security Hub findings for many AWS accounts and AWS Regions. Some of the accounts are in the company's organization, and some accounts are in organizations that the company manages for customers. Although the company can see findings in the Security Hub administrator account for accounts in the company's organization, there are no findings from accounts in other organizations. Which combination of steps should the company take to see findings from accounts that are outside the organization? (Select TWO)",
      "options": [
        "Use a designated administration account to automatically set up member accounts.",
        "Create the AWS Service Role For Security Hub service-linked role for Security Hub.",
        "Send an administration request from the member accounts.",
        "Enable Security Hub for all member accounts.",
        "Send invitations to accounts that are outside the company's organization from the Security Hub administrator account."
      ],
      "correct": [1, 4],
      "explanation": "✅ Correct: B - Service-linked role enables Security Hub to access accounts outside the organization; E - Invitations must be sent to accounts outside the organization to allow findings aggregation. ❌ Incorrect: A - Only applies to accounts inside the organization; C - Administration request from member accounts is insufficient; D - Enabling Security Hub alone does not grant cross-organization visibility.",
      "keywords": ["AWS Organizations", "Security Hub", "member accounts", "invitations", "service-linked role"]
    },
    {
      "id": 54,
      "type": "single",
      "question": "A company hosts a web application on an Apache Web server. The application runs on Amazon EC2 instances that are in an Auto Scaling group. The company configured the EC2 instances to send the Apache Web server logs to an Amazon CloudWatch Logs group. Recently, the company discovered in the Apache Web server logs that a specific IP address is sending suspicious requests to the Web application. A security engineer wants to analyze the past week of Apache Web server logs to determine how many requests that the IP address sent and the corresponding URLs. What should the security engineer do to meet these requirements with the LEAST effort?",
      "options": [
        "Export the CloudWatch Logs group data to Amazon S3. Use Amazon Macie to query the logs for the specific IP address and the requested URLs.",
        "Configure a CloudWatch Logs subscription to stream the log group to an Amazon OpenSearch Service cluster. Use OpenSearch Service to analyze the logs for the specific IP address and the requested URLs.",
        "Use CloudWatch Logs Insights and a custom query syntax to analyze the CloudWatch logs for the specific IP address and the requested URLs.",
        "Export the CloudWatch Logs group data to Amazon S3. Use AWS Glue to crawl the S3 bucket for only the log entries that contain the specific IP address."
      ],
      "correct": [2],
      "explanation": "✅ Correct: C - CloudWatch Logs Insights provides direct, quick analysis of logs with minimal setup. ❌ Incorrect: A - Macie is for sensitive data discovery, not log analysis; B - Streaming to OpenSearch works but requires more effort to set up and maintain; D - Using Glue is unnecessarily complex for a simple query.",
      "keywords": ["CloudWatch Logs", "Logs Insights", "query", "IP address", "URLs"]
    },
    {
      "id": 55,
      "type": "single",
      "question": "A company has multiple Amazon S3 buckets encrypted with customer-managed CMKs. Due to regulatory requirements, the keys must be rotated every year. The company's Security Engineer has enabled automatic key rotation for the CMKs; however, the company wants to verify that the rotation has occurred. What should the Security Engineer do to accomplish this?",
      "options": [
        "Filter AWS CloudTrail logs for KeyRotation events.",
        "Monitor Amazon CloudWatch Events for any AWS KMS CMK rotation events.",
        "Using the AWS CLI run the aws kms get-key-rotation-status operation with the –key-id parameter to check the CMK rotation date.",
        "Use Amazon Athena to query AWS CloudTrail logs saved in an S3 bucket to filter Generate New Key events."
      ],
      "correct": [2],
      "explanation": "✅ Correct: C - The KMS CLI command get-key-rotation-status returns the CMK's rotation state directly. ❌ Incorrect: A - CloudTrail shows events but requires filtering and is indirect; B - CloudWatch Events may alert on rotation, but verification is best done via CLI/API; D - Athena can query CloudTrail logs, but this is unnecessarily complex.",
      "keywords": ["S3", "CMK", "rotation", "KMS", "get-key-rotation-status"]
    },
    {
      "id": 56,
      "type": "single",
      "question": "A company has implemented AWS WAF and Amazon CloudFront for an application. The application runs on Amazon EC2 instances that are part of an Auto Scaling group. The Auto Scaling group is behind an Application Load Balancer (ALB). The AWS WAF web ACL uses an AWS Managed Rules rule group and is associated with the CloudFront distribution. During a security review, a security engineer discovers that the infrastructure is susceptible to a large, layer 7 DDoS attack. How can the security engineer improve the security at the edge of the solution to defend against this type of attack?",
      "options": [
        "Configure the CloudFront distribution to use the Lambda@Edge feature. Create an AWS Lambda function that imposes a rate limit on CloudFront viewer requests.",
        "Configure the AWS WAF web ACL so that the Web ACL has more capacity units to process all AWS WAF rules faster.",
        "Configure AWS WAF with a rate-based rule that imposes a rate limit that automatically blocks requests when the rate limit is exceeded.",
        "Configure the CloudFront distribution to use AWS WAF as its origin instead of the ALB."
      ],
      "correct": [2],
      "explanation": "✅ Correct: C - Rate-based WAF rules at the edge block excessive requests automatically. ❌ Incorrect: A - Lambda@Edge is more complex and less efficient for rate-limiting; B - Increasing capacity units doesn't prevent DDoS, only allows more rules to process; D - WAF cannot be an origin; CloudFront still needs ALB as origin.",
      "keywords": ["WAF", "CloudFront", "DDoS", "rate-based rule", "layer 7"]
    },
    {
      "id": 57,
      "type": "single",
      "question": "A company has multiple accounts in the AWS Cloud. Users in the developer account need to have access to specific resources in the production account. What is the MOST secure way to provide this access?",
      "options": [
        "Create one IAM user in the production account. Grant the appropriate permissions to the resources that are needed. Share the password only with the users that need access.",
        "Create cross account access with an IAM role in the developer account. Grant the appropriate permissions to this role. Allow users in the developer account to assume this role to access the production resources.",
        "Create cross-account access with an IAM user account in the production account. Grant the appropriate permissions to this user account. Allow users in the developer account to use this user account to access the production resources.",
        "Create cross-account access with an IAM role in the production account. Grant the appropriate permissions to this role. Allow users in the developer account to assume this role to access the production resources."
      ],
      "correct": [3],
      "explanation": "✅ Correct: D - Cross-account IAM role in production is the most secure and manageable method. ❌ Incorrect: A - Sharing passwords is insecure; B - Role in developer account cannot access production resources directly; C - Creating IAM users in production for developers is less secure and harder to manage.",
      "keywords": ["cross-account", "IAM role", "production", "developer", "assume role"]
    },
    {
      "id": 58,
      "type": "single",
      "question": "Amazon GuardDuty has detected communications to a known command and control endpoint from a company's Amazon EC2 instance. The instance was found to be running a vulnerable version of a common web framework. The company's security operations team wants to quickly identify other compute resources with the specific version of that framework installed. Which approach should the team take to accomplish this task?",
      "options": [
        "Scan all the EC2 instances for noncompliance with AWS Config. Use Amazon Athena to query AWS CloudTrail logs for the framework installation.",
        "Scan all the EC2 instances with the Amazon Inspector Network Reachability rules package to identify instances running a web server with RecognizedPortWithListener findings.",
        "Scan all the EC2 instances with AWS Systems Manager to identify the vulnerable version of the web framework.",
        "Scan all the EC2 instances with AWS Resource Access Manager to identify the vulnerable version of the web framework."
      ],
      "correct": [2],
      "explanation": "✅ Correct: C - AWS Systems Manager allows inventory and patch management, so you can quickly detect which instances have the vulnerable version. ❌ Incorrect: A - Config and CloudTrail cannot detect specific software versions installed; B - Inspector Network Reachability focuses on open ports, not software versions; D - RAM is for resource sharing, not for detecting installed software.",
      "keywords": ["GuardDuty", "vulnerable", "framework", "Systems Manager"]
    },
    {
      "id": 59,
      "type": "multiple",
      "question": "A company finds that one of its Amazon EC2 instances suddenly has high CPU usage. The company does not know whether the EC2 instance is compromised or whether the operating system is performing background cleanup. Which combination of steps should a security engineer take before investigating the issue? (Select THREE)",
      "options": [
        "Enable termination protection for the EC2 instance if termination protection has not been enabled.",
        "Take snapshots of the Amazon EBS data volumes that are attached to the EC2 instance.",
        "Capture the EC2 instance metadata, and then tag the EC2 instance as under quarantine.",
        "Disable termination protection for the EC2 instance if termination protection has not been disabled.",
        "Immediately remove any entries in the EC2 instance metadata that contain sensitive information."
      ],
      "correct": [0, 1, 2],
      "explanation": "✅ Correct: A - Protects the instance from accidental termination during investigation; B - Snapshots preserve the current state of data for forensic analysis; C - Capturing metadata and tagging helps with tracking and quarantine procedures. ❌ Incorrect: D - Disabling termination protection increases risk during investigation; E - Removing metadata may destroy evidence needed for investigation.",
      "keywords": ["high CPU", "snapshot", "metadata", "quarantine"]
    },
    {
      "id": 60,
      "type": "single",
      "question": "A company hosts an application on Amazon EC2 that is subject to specific rules for regulatory compliance. One rule states that traffic to and from the workload must be inspected for network-level attacks. To comply, a security engineer must install intrusion detection software on a c5n.4xlarge EC2 instance. The engineer must then configure the software to monitor traffic to and from the application instances. What should the security engineer do next?",
      "options": [
        "Place the network interface in promiscuous mode to capture the traffic.",
        "Configure VPC Flow Logs to send traffic to the monitoring EC2 instance using a Network Load Balancer.",
        "Configure VPC traffic mirroring to send traffic to the monitoring EC2 instance using a Network Load Balancer.",
        "Use Amazon Inspector to detect network-level attacks and trigger an AWS Lambda function to send the suspicious packets to the EC2 instance."
      ],
      "correct": [2],
      "explanation": "✅ Correct: C - VPC Traffic Mirroring allows sending a copy of network traffic to the monitoring instance for intrusion detection. ❌ Incorrect: A - Promiscuous mode on EC2 NICs does not scale or provide cross-instance visibility; B - Flow Logs provide metadata only, not full packet inspection; D - Inspector cannot provide full packet-level network monitoring.",
      "keywords": ["traffic mirroring", "intrusion detection", "network-level attacks"]
    },
    {
      "id": 61,
      "type": "single",
      "question": "A company has a relational database workload that runs on Amazon Aurora MySQL. According to new compliance standards, the company must rotate all database credentials every 30 days. The company needs a solution that maximizes security and minimizes development effort. Which solution will meet these requirements?",
      "options": [
        "Store the database credentials in AWS Secrets Manager. Configure automatic credential rotation for every 30 days.",
        "Store the database credentials in AWS Systems Manager Parameter Store. Create an AWS Lambda function to rotate the credentials every 30 days.",
        "Store the database credentials in an environment file or configuration file. Modify the credentials every 30 days.",
        "Store the database credentials in an environment file or configuration file. Create an AWS Lambda function to rotate the credentials every 30 days."
      ],
      "correct": [0],
      "explanation": "✅ Correct: A - Secrets Manager supports automated credential rotation with minimal development effort. ❌ Incorrect: B - Parameter Store requires custom Lambda code to rotate, more manual effort; C - Environment files are insecure and do not support automatic rotation; D - Environment files with Lambda rotation are more complex and error-prone.",
      "keywords": ["Aurora", "Secrets Manager", "credential rotation"]
    },
    {
      "id": 62,
      "type": "single",
      "question": "A company uses AWS Organizations to run workloads in multiple AWS accounts. Currently, the individual team members at the company access all Amazon EC2 instances remotely by using SSH or RDP. The company must secure access management and implement a centralized logging solution. Which solution will meet these requirements MOST securely?",
      "options": [
        "Configure trusted access for AWS Systems Manager in Organizations. Configure a bastion host from the management account. Replace SSH and RDP by using Systems Manager Session Manager from the management account.",
        "Replace SSH and RDP with AWS Systems Manager Session Manager. Install Systems Manager Agent (SSM Agent) on the instances. Attach the AmazonSSMManagedInstanceCore role to the instances. Configure session data streaming to Amazon CloudWatch Logs. Create a separate logging account that has appropriate cross-account permissions to audit the log data.",
        "Install a bastion host in the management account. Reconfigure all SSH and RDP to allow access only from the bastion host. Install AWS Systems Manager Agent (SSM Agent) on the bastion host.",
        "Replace SSH and RDP with AWS Systems Manager State Manager. Install Systems Manager Agent (SSM Agent) on the instances. Attach the AmazonSSMManagedInstanceCore role to the instances."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - Session Manager with centralized CloudWatch Logs streaming and a dedicated logging account provides secure access and auditing. ❌ Incorrect: A - Using a bastion host adds complexity and potential security risks; C - Bastion host approach is less secure and harder to manage at scale; D - State Manager with CloudTrail alone does not provide secure access and real-time logging.",
      "keywords": ["Session Manager", "centralized logging", "SSM Agent", "CloudWatch Logs"]
    },
    {
      "id": 63,
      "type": "multiple",
      "question": "An application team wants to use AWS Certificate Manager (ACM) to request public certificates to secure data in transit. The domains are not hosted on Route 53. The team wants a managed distribution and caching solution with a primary domain and alternative names, and certificates must renew automatically. Which combination of steps should the team take? (Select THREE)",
      "options": [
        "Request a certificate for ACM in the us-west-2 Region. Add the domain names that the certificate will secure.",
        "Send an email message to the domain administrators to request validation of the domains for ACM.",
        "Request validation of the domains for ACM through DNS. Insert CNAME records into each domain's DNS zone.",
        "Create an Application Load Balancer for the caching solution. Select the newly requested certificate from ACM for secure connections.",
        "Create an Amazon CloudFront distribution for the caching solution. Enter the main CNAME as the Origin Name, subdomain names as Alternate Domain Names, and select the ACM certificate for secure connections.",
        "Request a certificate from ACM in the us-east-1 Region. Add the domain names that the certificate will secure."
      ],
      "correct": [2, 4, 5],
      "explanation": "✅ Correct: C - DNS validation allows automated certificate renewal; E - CloudFront distribution with ACM certificate enables managed caching and secure access; F - us-east-1 ACM is required for CloudFront global certificates. ❌ Incorrect: A - Wrong region for CloudFront integration; B - Email validation doesn't allow automatic renewal; D - ALB is not required for this managed distribution + caching scenario.",
      "keywords": ["ACM", "CloudFront", "DNS validation", "certificate"]
    },
    {
      "id": 64,
      "type": "multiple",
      "question": "A company uses Amazon API Gateway for REST APIs. An API developer wants to analyze API access patterns without parsing log files. Which combination of steps will meet this requirement with the LEAST effort? (Select TWO)",
      "options": [
        "Configure access logging for the required API stage.",
        "Configure an AWS CloudTrail trail destination for API Gateway events with filters on userIdentity, userAgent, and sourceIPAddress.",
        "Configure an Amazon S3 destination for API Gateway logs. Run Amazon Athena queries to analyze API access.",
        "Use Amazon CloudWatch Logs Insights to analyze API access information.",
        "Select the Enable Detailed CloudWatch Metrics option on the required API stage."
      ],
      "correct": [0, 3],
      "explanation": "✅ Correct: A - Access logging at API stage captures all request details; D - CloudWatch Logs Insights allows analysis without parsing raw log files. ❌ Incorrect: B - CloudTrail logs API calls, not detailed request data; C - Athena queries work, but require extra effort compared to CloudWatch Logs Insights; E - Detailed CloudWatch Metrics are aggregated metrics, not detailed access info.",
      "keywords": ["API Gateway", "CloudWatch Logs Insights", "access logging"]
    },
    {
      "id": 65,
      "type": "single",
      "question": "A company needs to store multiple years of financial records in Amazon S3. The documents must not be edited, replaced, or deleted for 7 years and must be encrypted at rest. A security engineer creates a new S3 bucket. What should the engineer do next to meet these requirements?",
      "options": [
        "Configure S3 server-side encryption. Create a bucket policy with explicit deny rules for s3:DeleteObject and s3:PutObject. Configure S3 Object Lock in governance mode with 7-year retention.",
        "Configure S3 server-side encryption. Enable S3 Versioning. Configure S3 Object Lock in compliance mode with 7-year retention.",
        "Configure S3 Versioning and S3 Intelligent-Tiering. Use S3 server-side encryption. Expire objects after 7 years.",
        "Set up S3 Event Notifications with Lambda to deny s3:DeleteObject and s3:PutObject. Remove notifications after 7 years."
      ],
      "correct": [1],
      "explanation": "✅ Correct: B - Compliance mode Object Lock prevents deletion/modification for 7 years and ensures encryption at rest. ❌ Incorrect: A - Governance mode allows privileged users to bypass Object Lock, less strict than compliance mode; C - Intelligent-Tiering and expiration do not prevent deletion/modification; D - Lambda-based enforcement is not reliable for strict compliance requirements.",
      "keywords": ["S3 Object Lock", "compliance mode", "server-side encryption", "retention"]
    }
  ]
}